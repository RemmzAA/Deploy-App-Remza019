"""
REMZA019 Gaming - Real-time YouTube Synchronization System
Advanced YouTube integration without API dependency
"""
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
from motor.motor_asyncio import AsyncIOMotorClient
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class YouTubeSyncManager:
    def __init__(self):
        self.channel_url = "https://www.youtube.com/@remza019"
        self.channel_videos_url = "https://www.youtube.com/@remza019/videos"
        self.channel_live_url = "https://www.youtube.com/@remza019/streams"
        self.db = None
        
    async def initialize_db(self):
        """Initialize database connection"""
        try:
            mongodb_url = os.environ.get('MONGO_URL')
    if not mongodb_url:
        raise ValueError("MONGO_URL environment variable is required")
            client = AsyncIOMotorClient(mongodb_url)
            # Use database name from environment or extract from URL
            db_name = os.environ.get('DB_NAME', 'remza019_gaming')
            self.db = client[db_name]
            logger.info("‚úÖ YouTube Sync database initialized")
        except Exception as e:
            logger.error(f"‚ùå Database initialization error: {e}")
            
    async def fetch_channel_page(self, url: str) -> Optional[str]:
        """Fetch YouTube channel page content"""
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'en-US,en;q=0.5',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                }
                
                async with session.get(url, headers=headers) as response:
                    if response.status == 200:
                        content = await response.text()
                        logger.info(f"‚úÖ Successfully fetched: {url}")
                        return content
                    else:
                        logger.error(f"‚ùå Failed to fetch {url}: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"‚ùå Error fetching {url}: {e}")
            return None

    def extract_channel_data(self, html_content: str) -> Dict:
        """Extract channel data from HTML content"""
        try:
            # Extract subscriber count from various possible locations
            subscriber_patterns = [
                r'"subscriberCountText":{"simpleText":"([^"]+)"',
                r'"subscriberCountText":{"runs":\[{"text":"([^"]+)"',
                r'subscribers?["\s]*[:\s]*["\s]*([0-9.,KMB]+)',
                r'([0-9.,KMB]+)\s*subscribers?'
            ]
            
            subscriber_count = "178"  # Default fallback
            for pattern in subscriber_patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    subscriber_count = match.group(1).strip()
                    break
            
            # Extract video count
            video_patterns = [
                r'"videoCountText":{"simpleText":"([^"]+)"',
                r'([0-9,]+)\s*videos?'
            ]
            
            video_count = "15"  # Default fallback
            for pattern in video_patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    video_count = match.group(1).strip()
                    break
            
            # Extract view count
            view_patterns = [
                r'"viewCountText":{"simpleText":"([^"]+)"',
                r'([0-9.,KMB]+)\s*views?'
            ]
            
            view_count = "3247"  # Default fallback
            for pattern in view_patterns:
                match = re.search(pattern, html_content, re.IGNORECASE)
                if match:
                    view_count = match.group(1).strip()
                    break
            
            # Check for live stream status
            is_live = False
            live_viewers = "0"
            
            live_patterns = [
                r'"isLiveContent":true',
                r'"badges":\[{"metadataBadgeRenderer":{"style":"BADGE_STYLE_TYPE_LIVE_NOW"',
                r'LIVE\s*NOW',
                r'live\s*stream'
            ]
            
            for pattern in live_patterns:
                if re.search(pattern, html_content, re.IGNORECASE):
                    is_live = True
                    break
            
            # Extract viewer count if live
            if is_live:
                viewer_patterns = [
                    r'"viewerCount":{"videoViewCountRenderer":{"viewCount":{"simpleText":"([^"]+)"',
                    r'([0-9,]+)\s*watching',
                    r'([0-9,]+)\s*viewers?'
                ]
                
                for pattern in viewer_patterns:
                    match = re.search(pattern, html_content, re.IGNORECASE)
                    if match:
                        live_viewers = match.group(1).strip()
                        break
            
            return {
                'subscriber_count': self._clean_count(subscriber_count),
                'video_count': self._clean_count(video_count), 
                'view_count': self._clean_count(view_count),
                'is_live': is_live,
                'live_viewers': self._clean_count(live_viewers),
                'last_updated': datetime.now(),
                'sync_status': 'success'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting channel data: {e}")
            return {
                'subscriber_count': '178',
                'video_count': '15', 
                'view_count': '3247',
                'is_live': False,
                'live_viewers': '0',
                'last_updated': datetime.now(),
                'sync_status': 'error'
            }
    
    def _clean_count(self, count_str: str) -> str:
        """Clean and normalize count strings"""
        if not count_str:
            return "0"
        
        # Remove extra spaces and non-numeric characters except K, M, B
        cleaned = re.sub(r'[^\d.,KMB]', '', str(count_str).upper())
        
        # Handle K, M, B suffixes
        if 'K' in cleaned:
            try:
                num = float(cleaned.replace('K', ''))
                return str(int(num * 1000))
            except:
                return cleaned.replace('K', '')
        elif 'M' in cleaned:
            try:
                num = float(cleaned.replace('M', ''))
                return str(int(num * 1000000))
            except:
                return cleaned.replace('M', '')
        elif 'B' in cleaned:
            try:
                num = float(cleaned.replace('B', ''))
                return str(int(num * 1000000000))
            except:
                return cleaned.replace('B', '')
        
        return cleaned or "0"
    
    def extract_recent_videos(self, html_content: str) -> List[Dict]:
        """Extract recent videos from channel page"""
        try:
            videos = []
            
            # Look for video data in the HTML
            video_patterns = [
                r'"videoId":"([^"]+)".*?"title":{"runs":\[{"text":"([^"]+)".*?"lengthText":{"simpleText":"([^"]+)".*?"viewCountText":{"simpleText":"([^"]+)"',
                r'"videoId":"([^"]+)".*?"title":"([^"]+)".*?"lengthText":"([^"]+)".*?"viewCount":"([^"]+)"'
            ]
            
            for pattern in video_patterns:
                matches = re.findall(pattern, html_content, re.DOTALL)
                for match in matches:
                    if len(match) >= 4:
                        video_id, title, duration, views = match[:4]
                        
                        videos.append({
                            'id': video_id,
                            'video_id': video_id,
                            'title': title[:100],  # Limit title length
                            'description': f'REMZA019 Gaming video: {title[:50]}...',
                            'thumbnail_url': f'https://img.youtube.com/vi/{video_id}/hqdefault.jpg',
                            'watch_url': f'https://www.youtube.com/watch?v={video_id}',
                            'view_count': self._clean_count(views),
                            'duration': duration,
                            'published_at': datetime.now().isoformat()
                        })
                
                if videos:
                    break  # Use first successful pattern
            
            # If no videos found, return fallback data
            if not videos:
                videos = self._get_fallback_videos()
                
            return videos[:10]  # Return max 10 videos
            
        except Exception as e:
            logger.error(f"‚ùå Error extracting videos: {e}")
            return self._get_fallback_videos()
    
    def _get_fallback_videos(self) -> List[Dict]:
        """Fallback video data"""
        return [
            {
                'id': 'GUhc9NBBxBM',
                'video_id': 'GUhc9NBBxBM',
                'title': 'REMZA019 - UNLUCKY (Channel Presentation)',
                'description': 'REMZA019 channel presentation video! Subscribe and like for more gaming content from Serbia.',
                'thumbnail_url': 'https://img.youtube.com/vi/GUhc9NBBxBM/hqdefault.jpg',
                'watch_url': 'https://www.youtube.com/watch?v=GUhc9NBBxBM',
                'view_count': '156',
                'duration': 'PT18M33S',
                'published_at': '2024-09-10T20:00:00Z'
            },
            {
                'id': 'h1HGztOJgHo',
                'video_id': 'h1HGztOJgHo',
                'title': 'REMZA019 - UNLUCKY 2',
                'description': 'UNLUCKY 2 gaming session from Serbia! Authentic REMZA019 gaming content.',
                'thumbnail_url': 'https://img.youtube.com/vi/h1HGztOJgHo/hqdefault.jpg',
                'watch_url': 'https://www.youtube.com/watch?v=h1HGztOJgHo',
                'view_count': '103',
                'duration': 'PT15M42S',
                'published_at': '2024-09-15T19:30:00Z'
            }
        ]
    
    async def sync_channel_data(self) -> Dict:
        """Perform complete channel sync"""
        try:
            logger.info("üîÑ Starting YouTube channel sync...")
            
            # Fetch main channel page
            main_content = await self.fetch_channel_page(self.channel_url)
            videos_content = await self.fetch_channel_page(self.channel_videos_url)
            
            if not main_content:
                logger.error("‚ùå Could not fetch channel content")
                return {'success': False, 'error': 'Failed to fetch channel'}
            
            # Extract channel data
            channel_data = self.extract_channel_data(main_content)
            
            # Extract videos
            videos = self.extract_recent_videos(videos_content or main_content)
            
            # Save to database
            if self.db is not None:
                await self._save_sync_data(channel_data, videos)
            
            logger.info("‚úÖ YouTube sync completed successfully")
            
            return {
                'success': True,
                'channel_data': channel_data,
                'videos': videos,
                'sync_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Sync error: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _save_sync_data(self, channel_data: Dict, videos: List[Dict]):
        """Save sync data to database - RESPECT ADMIN MANUAL OVERRIDES"""
        try:
            # Check if admin has manually set values
            current_stats = await self.db.channel_stats.find_one({})
            
            # Create update dict with only auto-sync fields
            update_fields = {
                'subscriber_count': channel_data.get('subscriber_count'),
                'video_count': channel_data.get('video_count'),
                'view_count': channel_data.get('view_count'),
                'last_updated': channel_data.get('last_updated'),
                'sync_status': channel_data.get('sync_status')
            }
            
            # ONLY update is_live and live_viewers if admin hasn't manually overridden
            if current_stats:
                admin_override = current_stats.get('admin_override', False)
                
                if not admin_override:
                    # No admin override - sync can update live status
                    update_fields['is_live'] = channel_data.get('is_live', False)
                    update_fields['live_viewers'] = channel_data.get('live_viewers', '0')
                else:
                    # Admin has overridden - keep existing values
                    logger.info("‚ö†Ô∏è Admin override active - skipping live status sync")
            else:
                # First time sync - set all fields
                update_fields['is_live'] = channel_data.get('is_live', False)
                update_fields['live_viewers'] = channel_data.get('live_viewers', '0')
            
            # Update channel stats
            await self.db.channel_stats.update_one(
                {},
                {'$set': update_fields},
                upsert=True
            )
            
            # Update recent videos
            for video in videos:
                await self.db.recent_videos.update_one(
                    {'video_id': video['video_id']},
                    {'$set': video},
                    upsert=True
                )
                
            logger.info("‚úÖ Sync data saved to database (respecting admin overrides)")
            
        except Exception as e:
            logger.error(f"‚ùå Error saving sync data: {e}")

# Initialize sync manager
youtube_sync = YouTubeSyncManager()

async def start_sync_scheduler():
    """Start background sync scheduler"""
    try:
        await youtube_sync.initialize_db()
        
        # Run sync every 5 minutes
        while True:
            try:
                result = await youtube_sync.sync_channel_data()
                if result['success']:
                    logger.info("üîÑ Scheduled sync completed")
                else:
                    logger.error(f"‚ùå Scheduled sync failed: {result.get('error')}")
            except Exception as e:
                logger.error(f"‚ùå Sync scheduler error: {e}")
            
            # Wait 5 minutes before next sync
            await asyncio.sleep(300)
            
    except Exception as e:
        logger.error(f"‚ùå Sync scheduler initialization error: {e}")

def get_sync_manager():
    """Get YouTube sync manager instance"""
    return youtube_sync